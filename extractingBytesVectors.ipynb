{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os, pickle\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import time, json, sys"
   ]
  },
  {
   "source": [
    "# 1 gram"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_bytes(chunksize, rootdir):\n",
    "    mega_dict = dict()\n",
    "    start = time.time()\n",
    "    file_index = 0\n",
    "    for subdir, dirs, files in os.walk(rootdir):\n",
    "        for file_name in files:\n",
    "            filepath = os.path.abspath(os.path.join(subdir, file_name))\n",
    "            file_dict = dict()\n",
    "            f = open(filepath, \"rb\")\n",
    "            contents = f.read(chunksize)\n",
    "            contents = np.frombuffer(contents, dtype=np.uint8)\n",
    "           \n",
    "            if len(contents) < chunksize:\n",
    "                contents = np.pad(contents, (0, chunksize - len(contents)), constant_values=0)\n",
    "\n",
    "            f.close()\n",
    "\n",
    "            mega_dict[filepath] = contents\n",
    "\n",
    "            file_index += 1\n",
    "            if file_index % 2000 == 0:\n",
    "                print('done with 2000')\n",
    "    end = time.time()\n",
    "    time_elapsed = end - start\n",
    "    print(\"For chunksize: {cs} bytes Time elapsed was: {te} seconds\".format(cs=chunksize, te=time_elapsed))\n",
    "    return mega_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "done with 2000\n",
      "done with 2000\n",
      "done with 2000\n",
      "done with 2000\n",
      "done with 2000\n",
      "done with 2000\n",
      "done with 2000\n",
      "done with 2000\n",
      "done with 2000\n",
      "done with 2000\n",
      "For chunksize: 512 bytes Time elapsed was: 0.4505293369293213 seconds\n"
     ]
    }
   ],
   "source": [
    "mega_dict = analyze_bytes(512, '../CDIACPub8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CDIACFileData/ByteVectors/byte_vector_dict_512B.pkl', 'wb+') as handle:\n",
    "    pickle.dump(mega_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CDIACFileData/ByteVectors/byte_vector_dict_256KB.pkl', 'rb') as handle:\n",
    "    mega_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "mega_array = np.array([item for item in mega_dict.values()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(20427, 262144)\n"
     ]
    }
   ],
   "source": [
    "print(mega_array.shape)"
   ]
  },
  {
   "source": [
    "# 2 - gram"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bytes_to_two_grams(bytes_object, chunksize):\n",
    "    if len(bytes_object) == 0:\n",
    "        contents = np.zeros(chunksize - 1)\n",
    "    else:\n",
    "        contents = np.zeros(len(bytes_object) - 1, dtype=np.uint8) # number of adjacent pairs is always length - 1\n",
    "        for i in range(len(bytes_object) - 1):\n",
    "            contents[i] = bytes_object[i] * 256 + bytes_object[i+1]\n",
    "    return contents\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_bytes_2grams(chunksize, rootdir):\n",
    "    mega_dict = dict()\n",
    "    start = time.time()\n",
    "    file_index = 0\n",
    "    for subdir, dirs, files in os.walk(rootdir):\n",
    "        for file_name in files:\n",
    "            filepath = os.path.abspath(os.path.join(subdir, file_name))\n",
    "            file_dict = dict()\n",
    "            f = open(filepath, \"rb\")\n",
    "            contents = f.read(chunksize)\n",
    "            contents = convert_bytes_to_two_grams(contents, chunksize)\n",
    "           \n",
    "            if len(contents) - 1 < chunksize:\n",
    "                contents = np.pad(contents, (0, chunksize - len(contents) - 1), constant_values=0)\n",
    "\n",
    "            f.close()\n",
    "\n",
    "            mega_dict[filepath] = contents\n",
    "\n",
    "            file_index += 1\n",
    "            if file_index % 2000 == 0:\n",
    "                print('done with 2000')\n",
    "\n",
    "    end = time.time()\n",
    "    time_elapsed = end - start\n",
    "    print(\"For chunksize: {cs} bytes Time elapsed was: {te} seconds\".format(cs=chunksize, te=time_elapsed))\n",
    "    return mega_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "done with 2000\n",
      "done with 2000\n",
      "done with 2000\n",
      "done with 2000\n",
      "done with 2000\n",
      "done with 2000\n",
      "done with 2000\n",
      "done with 2000\n",
      "done with 2000\n",
      "done with 2000\n",
      "For chunksize: 512 bytes Time elapsed was: 2.435601234436035 seconds\n"
     ]
    }
   ],
   "source": [
    "mega_dict_2grams = analyze_bytes_2grams(512, '../CDIACPub8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CDIACFileData/ByteVectors/byte_vector_dict_512B_2grams.pkl', 'wb+') as handle:\n",
    "    pickle.dump(mega_dict_2grams, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ]
}